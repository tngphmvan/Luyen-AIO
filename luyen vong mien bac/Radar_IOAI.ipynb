{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94b4f7a3",
   "metadata": {},
   "source": [
    "# Radar\n",
    "\n",
    "## 1. Mô tả bài toán\n",
    "\n",
    "Radar là một công nghệ then chốt trong truyền thông vô tuyến, có nhiều ứng dụng như xe tự hành. Nó thường gồm một anten phát các tín hiệu nhất định và thu lại các tín hiệu phản xạ từ các vật thể xung quanh. Bằng cách xử lý các tín hiệu này, hệ thống có thể xác định phương hướng góc, khoảng cách và vận tốc của các mục tiêu.\n",
    "\n",
    "Trong ứng dụng thực tế, xử lý tín hiệu radar gặp nhiều khó khăn do nhiễu và các phản xạ từ những vật thể không phải mục tiêu trong môi trường. Ví dụ, khi cố gắng phát hiện người đi bộ, radar có thể đồng thời thu được phản xạ từ cây cối hoặc các vật nền khác, làm giảm độ chính xác. Nhiệm vụ của bạn là dùng AI để phân tích các tín hiệu thu được từ radar và xác định xem tại mỗi vị trí có con người hay không.\n",
    "\n",
    "Trong bài này chúng tôi cung cấp một **bộ dữ liệu thí nghiệm radar trong nhà**, và mục tiêu của bạn là phát triển một mô hình thực hiện **phân đoạn ngữ nghĩa (semantic segmentation)** trên dữ liệu radar.\n",
    "\n",
    "## 2. Bộ dữ liệu\n",
    "\n",
    "Để đo các vật thể xung quanh radar, các tham số chính sau được sử dụng:\n",
    "\n",
    "* **Range (khoảng cách)**: Khoảng cách thẳng giữa radar và một vật thể.\n",
    "* **Azimuth (phương vị)**: Góc ngang (trái sang phải) giữa radar và vật thể.\n",
    "* **Elevation (độ cao / góc chiều dọc)**: Góc thẳng đứng (lên hoặc xuống) của vật thể so với radar.\n",
    "* **Velocity (vận tốc)**: Tốc độ vật thể đang tiến tới hay lùi khỏi radar.\n",
    "\n",
    "<img src=\"figs/Radar Fig 1.png\" width=\"300\">\n",
    "\n",
    "Dữ liệu radar được xử lý thành nhiều **bản đồ nhiệt (heatmaps)**, mỗi bản mã hóa **cường độ tín hiệu nhận được** ở các vị trí và hướng khác nhau.\n",
    "\n",
    "* **Bản đồ nhiệt tĩnh (static heatmaps)** nhấn mạnh các phản xạ từ các vật thể **đứng yên**.\n",
    "* **Bản đồ nhiệt động (dynamic heatmaps)** làm nổi bật các thay đổi do **vật thể chuyển động** gây ra.\n",
    "\n",
    "Khi không có vật thể tại một vị trí cụ thể, tín hiệu chủ yếu là nhiễu nền và xuất hiện yếu. Ngược lại, phản xạ từ một vật thể sẽ làm tăng cường độ tín hiệu, cho phép phát hiện vật thể đó.\n",
    "\n",
    "Ví dụ, **bản đồ nhiệt khoảng cách–phương vị tĩnh (static range-azimuth heatmap)** thể hiện cường độ tín hiệu theo các khoảng cách (**range**) và các góc ngang (**azimuth**), chủ yếu là phản xạ từ các vật thể tĩnh.\n",
    "\n",
    "Mỗi mẫu trong bộ dữ liệu được lưu trong file `.mat.pt` dưới dạng tensor có kích thước $7 \\times 50 \\times 181$, trong đó:\n",
    "\n",
    "* 7 là số bản đồ (6 bản đồ nhiệt + 1 bản đồ nhãn ngữ nghĩa),\n",
    "* 50 tương ứng với số bin khoảng cách (range bins),\n",
    "* 181 tương ứng với số bin góc hoặc vận tốc, bao phủ góc từ -90° đến +90° trong mặt phẳng ngang hoặc dọc. Bạn có thể giả định rằng các bin vận tốc cũng được ánh xạ lại từ -90° đến +90° để tiện trực quan hóa.\n",
    "* mỗi giá trị cường độ trên bản đồ nhiệt đã được chuẩn hóa về [0, 1], biểu diễn cường độ tín hiệu nhận được.\n",
    "\n",
    "6 bản đồ nhiệt được cấu trúc như sau:\n",
    "\n",
    "* **Chỉ số 0**: Bản đồ tĩnh khoảng cách–phương vị (static range-azimuth heatmap)\n",
    "* **Chỉ số 1**: Bản đồ động khoảng cách–phương vị (dynamic range-azimuth heatmap)\n",
    "* **Chỉ số 2**: Bản đồ tĩnh khoảng cách–độ cao (static range-elevation heatmap)\n",
    "* **Chỉ số 3**: Bản đồ động khoảng cách–độ cao (dynamic range-elevation heatmap)\n",
    "* **Chỉ số 4**: Bản đồ tĩnh khoảng cách–vận tốc (static range-velocity heatmap)\n",
    "* **Chỉ số 5**: Bản đồ động khoảng cách–vận tốc (dynamic range-velocity heatmap)\n",
    "\n",
    "Tất cả giá trị trong các bản đồ nhiệt đều **đã được chuẩn hóa**, nên không cần chuyển đổi đơn vị.\n",
    "\n",
    "**Bản đồ ở Chỉ số 6** là bản đồ nhãn ngữ nghĩa, lưu ở định dạng range-azimuth.\n",
    "\n",
    "* **-1**: Nền (không có mục tiêu)\n",
    "* **0**: Va-li (suitcase)\n",
    "* **1**: Ghế (chair)\n",
    "* **2**: Người (human)\n",
    "* **3**: Tường (wall)\n",
    "\n",
    "Đây là trực quan hóa file `1.mat.pt` trong `training_set`:\n",
    "\n",
    "<img src=\"figs/Radar Fig 2.png\" width=\"675\">\n",
    "\n",
    "Một phần mẫu dữ liệu:\n",
    "\n",
    "<img src=\"figs/Radar Fig 3.png\" width=\"675\">\n",
    "\n",
    "Quy mô dữ liệu: 1800 mẫu trong tập huấn luyện, 500 mẫu trong tập validation, và 500 mẫu trong tập test.\n",
    "\n",
    "## 3. Nhiệm vụ\n",
    "\n",
    "Nhiệm vụ của bạn là phát triển một mô hình nhận **sáu bản đồ nhiệt đầu tiên** (các chỉ số 0 đến 5) làm đầu vào, và dự đoán **bản đồ nhãn ngữ nghĩa** (chỉ số 6) làm đầu ra. Mục tiêu là xác định chính xác nhãn (từ -1 đến 3) tại mỗi vị trí trong trường nhìn của radar.\n",
    "\n",
    "1. **Input**: Tensor có kích thước $6 \\times 50 \\times 181$, đại diện cho sáu bản đồ nhiệt radar.\n",
    "2. **Output**: Tensor có kích thước $50 \\times 181$, đại diện cho bản đồ nhãn ngữ nghĩa (label map).\n",
    "\n",
    "## 4. Nộp bài\n",
    "\n",
    "Vui lòng nộp một file tên `submission.ipynb`. Kết quả đầu ra là một file zip tên `submission.zip`, chứa hai bảng `submission_val.csv` và `submission_test.csv` tương ứng với kết quả dự đoán trên tập validation và tập test.\n",
    "\n",
    "**Lưu ý:** Bảng kết quả chỉ cần có header; dữ liệu trong bảng không nhất thiết là dữ liệu đã giải xong, nó chỉ dùng làm ví dụ về định dạng nộp bài.\n",
    "\n",
    "| filename | pixel_0 | pixel_1 | ... | pixel_9049 |\n",
    "| :------: | :-----: | ------- | --- | ---------- |\n",
    "| 1.mat.pt |    -1   | -1      | ... | -1         |\n",
    "|    ...   |   ...   | ...     | ... | ...        |\n",
    "\n",
    "## 5. Điểm số\n",
    "\n",
    "Điểm được tính dựa trên **độ chính xác nhận diện nhãn**. Việc phát hiện đúng các điểm là mục tiêu (non-background) được tính trọng số lớn hơn so với việc nhận diện đúng các điểm nền.\n",
    "\n",
    "### Tiêu chí chấm:\n",
    "\n",
    "* Mỗi pixel nền (background) dự đoán đúng được **1 điểm**.\n",
    "* Mỗi pixel không phải nền (non-background) dự đoán đúng được **50 điểm**.\n",
    "* Điểm cuối cùng được chuẩn hóa về thang **0–1** bằng cách so sánh với điểm tối đa có thể đạt được.\n",
    "\n",
    "### Công thức：\n",
    "\n",
    "$$\n",
    "Score = \\frac{|C_{0,correct}| \\times 1 + |C_{1,correct}| \\times bonus}{|C_0| \\times 1 + |C_1| \\times bonus}\n",
    "$$\n",
    "với:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "I &= {1, 2, \\dots, 50\\times 181}\\\n",
    "C_0 &= {i \\in I \\mid y_i = -1}\\\n",
    "C_1 &= {i \\in I \\mid y_i \\neq -1}\\\n",
    "C_{0,correct} &= {i \\in C_0 \\mid p_i = y_i}\\\n",
    "C_{1,correct} &= {i \\in C_1 \\mid p_i = y_i}\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Ví dụ\n",
    "\n",
    "Với bản đồ $3\\times3$, giả sử Ground Truth là:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "-1 & -1 & -1 \\\n",
    "1 & 2 & 3 \\\n",
    "-1 & -1 & -1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Kết quả mong muốn là:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "-1 & 1 & -1 \\\n",
    "-1 & 2 & -1 \\\n",
    "-1 & 3 & -1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Khi đó có bốn pixel `-1` dự đoán đúng và một pixel `2` dự đoán đúng. Điểm của bạn là 4 + 50 = 54. Điểm tối đa có thể là 6 + 50 * 3 = 156 (tức là 6 pixel nền và 3 pixel non-background). Điểm chuẩn hóa là 54 / 156 = 0.346.\n",
    "\n",
    "$$\n",
    "Score = \\frac{4 \\times 1 + 1 \\times 50}{6 \\times 1 + 3 \\times 50}=0.346\n",
    "$$\n",
    "\n",
    "## 6. Baseline và Tập huấn luyện\n",
    "\n",
    "* Dưới đây bạn có thể tìm giải pháp baseline.\n",
    "* Bộ dữ liệu nằm trong thư mục `training_set`.\n",
    "* Điểm cao nhất do Ban khoa học đạt được cho bài này là 0.90 trên Leaderboard B; điểm này dùng để chuẩn hóa điểm.\n",
    "* Điểm baseline do Ban khoa học cho là 0.67 trên Leaderboard B; điểm này cũng dùng để chuẩn hóa điểm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd4dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_path = os.getenv(\"radar_path\")\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tensor = torch.load(f\"{data_path}/training_set/1.mat.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f5e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(tensor.numpy().shape[0]):\n",
    "    plt.imshow(tensor.numpy()[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a927de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "model = deeplabv3_resnet50(weights = None, weights_backbone=None, num_classes=5)\n",
    "print(model.backbone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e575c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torch.nn import Conv2d\n",
    "from torch import nn\n",
    "class EfficientNetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Get EfficientNet features only\n",
    "        backbone = efficientnet_b0(weights=False)\n",
    "        \n",
    "        # Modify first conv layer for 6 input channels\n",
    "        backbone.features[0][0] = Conv2d(6, 32, (3,3), (2,2), (1,1), bias=False)\n",
    "        \n",
    "        # Use only features part\n",
    "        self.features = backbone.features\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Process features and return dict format expected by DeepLabV3\n",
    "        x = self.features(x)\n",
    "        return {\"out\": x}\n",
    "model = deeplabv3_resnet50(weights=None, weights_backbone=None, num_classes=5)\n",
    "model.backbone = EfficientNetBackbone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190bdc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = EfficientNet_B0_Weights.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c38f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import torchvision\n",
    "functions = inspect.getmembers(torchvision, inspect.isfunction)\n",
    "for name, func in functions:\n",
    "    print(name)\n",
    "# Liệt kê tất cả hàm trong torchvision.utils\n",
    "import torchvision.utils as utils\n",
    "functions = inspect.getmembers(utils, inspect.isfunction)\n",
    "\n",
    "for name, func in functions:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb9aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.load(f\"{data_path}/Solution/validation_set/1.mat.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c5aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(f\"{data_path}/Solution/validation_set/labels/ground_truth_val.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(os.listdir(f\"{data_path}/training_set\"))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tensor = torch.load(os.path.join(f\"{data_path}/training_set\", f\"{idx+1}.mat.pt\"))\n",
    "        if self.transform:\n",
    "            tensor = self.transform(tensor)\n",
    "        label = tensor[-1] + 1\n",
    "        return {'data': tensor[:-1].float(), 'label': label.long()}\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_path, label_path, transform=None):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        self.data_path = data_path\n",
    "        self.labels = pd.read_csv(label_path)\n",
    "    def __len__(self):\n",
    "        files = [file for file in os.listdir(self.data_path) if file.endswith('.pt')]\n",
    "        return len(files)\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.load(os.path.join(self.data_path, f\"{idx+1}.mat.pt\"))\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        label_row = self.labels[self.labels['filename'] == f\"{idx+1}.mat.pt\"]\n",
    "        if not label_row.empty:\n",
    "            pixel_columns = [col for col in self.labels.columns if col.startswith('pixel_')]\n",
    "            label = torch.tensor(label_row[pixel_columns].values[0], dtype=torch.long)\n",
    "            label = label.reshape(50,181)\n",
    "            label = label+1\n",
    "\n",
    "        return {\n",
    "            'data': data.float(),\n",
    "            'label': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TrainDataset()\n",
    "public_test_dataset = TestDataset(f\"{data_path}/Solution/validation_set\", f\"{data_path}/Solution/validation_set/labels/ground_truth_val.csv\")\n",
    "private_test_dataset = TestDataset(f\"{data_path}/Solution/test_set\", f\"{data_path}/Solution/test_set/labels/ground_truth_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318a3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(42, workers=4, verbose=False)\n",
    "train_size = int(len(dataset) * 0.2)\n",
    "valid_size = len(dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(dataset=dataset, lengths=[train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e4d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, tv_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaeef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=36,\n",
    "                            #   sampler=\n",
    "                            shuffle=True,\n",
    "                            num_workers=0\n",
    "                            )\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset,\n",
    "                              batch_size=36,\n",
    "                            #   sampler=\n",
    "                            shuffle=True,\n",
    "                            num_workers=0\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab259683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b0\n",
    "from torch.nn import Conv2d\n",
    "from torch import nn\n",
    "\n",
    "class EfficientNetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Get EfficientNet features only\n",
    "        backbone = efficientnet_b0(weights=False)\n",
    "        \n",
    "        # Modify first conv layer for 6 input channels\n",
    "        backbone.features[0][0] = Conv2d(6, 32, (3,3), (2,2), (1,1), bias=False)\n",
    "        \n",
    "        # Use only features part\n",
    "        self.features = backbone.features\n",
    "        \n",
    "        # Add adapter layer to convert 1280 -> 2048 channels\n",
    "        self.adapter = Conv2d(1280, 2048, kernel_size=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Process features\n",
    "        x = self.features(x)\n",
    "        # Convert channels to match DeepLabV3 expectations\n",
    "        x = self.adapter(x)\n",
    "        return {\"out\": x}\n",
    "\n",
    "model = deeplabv3_resnet50(weights=None, weights_backbone=None, num_classes=5)\n",
    "model.backbone = EfficientNetBackbone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda0baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        # ✅ SỬA: Register alpha as buffer để tự động chuyển device\n",
    "        # self.register_buffer('alpha', torch.tensor([0.05, 1.0, 1.0, 1.0, 1.0]))\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        alpha = torch.tensor([len(targets)/len(targets[targets == i]) for i in range(5)], device=inputs.device)\n",
    "        # ✅ SỬA: alpha đã tự động trên cùng device với inputs\n",
    "        alpha_t = alpha[targets]\n",
    "        focal_loss = alpha_t * (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        return focal_loss.mean()\n",
    "\n",
    "def scoring(y_pred: torch.Tensor, y_true: torch.Tensor):\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_true = y_true.flatten()\n",
    "    \n",
    "    bg_mask = (y_true == 0)\n",
    "    object_mask = (y_true != 0)\n",
    "    \n",
    "    son = (y_pred[bg_mask] == y_true[bg_mask]).sum() * 1 + (y_pred[object_mask] == y_true[object_mask]).sum() * 50\n",
    "    mother = (bg_mask.sum()*1 + object_mask.sum() * 50)\n",
    "    if mother == 0:\n",
    "        return 0.0\n",
    "    return (son/mother).float()\n",
    "class WrapperModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = model\n",
    "        self.criterion = FocalLoss()\n",
    "        self.validation_preds = []\n",
    "        self.validation_labels = []\n",
    "        self.train_preds = []\n",
    "        self.train_labels = []\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def training_step(self, batch, idx):\n",
    "        y_hat = self(batch['data'])['out']\n",
    "        y_true = batch['label'].to('cuda')\n",
    "        loss = self.criterion(y_hat, y_true)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        preds = torch.argmax(y_hat, dim=1).detach().cpu().numpy().flatten()\n",
    "        targets = y_true.detach().cpu().numpy().flatten()\n",
    "        self.log(\"accuracy\", accuracy_score(targets, preds))\n",
    "        self.log(\"precision\", precision_score(targets, preds, average='micro'))\n",
    "        self.log(\"recall\", recall_score(targets, preds, average='micro'))\n",
    "        self.log(\"f1-score\", f1_score(targets, preds, average='micro'))\n",
    "        self.train_preds.append(torch.argmax(y_hat, dim=1).detach().cpu())\n",
    "        self.train_labels.append(y_true.detach().cpu())\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        all_preds = torch.cat(self.train_preds)\n",
    "        all_labels = torch.cat(self.train_labels)\n",
    "\n",
    "        score = scoring(all_preds.flatten(), all_labels.flatten())\n",
    "        self.log(\"train_score\", score)\n",
    "        self.train_preds.clear()\n",
    "        self.train_labels.clear()\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y_hat = self(batch['data'])['out']\n",
    "        y_true = batch['label']\n",
    "        loss = self.criterion(y_hat, y_true.to(y_hat.device))\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        preds = torch.argmax(y_hat, dim=1).detach().cpu().numpy().flatten()\n",
    "        targets = y_true.detach().cpu().numpy().flatten()\n",
    "        self.log(\"accuracy\", accuracy_score(targets, preds))\n",
    "        self.log(\"precision\", precision_score(targets, preds, average='micro'))\n",
    "        self.log(\"recall\", recall_score(targets, preds, average='micro'))\n",
    "        self.log(\"f1-score\", f1_score(targets, preds, average='micro'))\n",
    "        self.validation_preds.append(torch.argmax(y_hat, dim=1).detach().cpu())\n",
    "        self.validation_labels.append(y_true.detach().cpu())\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        all_preds = torch.cat(self.validation_preds)\n",
    "        all_labels = torch.cat(self.validation_labels)\n",
    "\n",
    "        score = scoring(all_preds.flatten(), all_labels.flatten())\n",
    "        self.log(\"val_score\", score, prog_bar=True)\n",
    "        cm = confusion_matrix(all_labels.flatten(), all_preds.flatten())\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(cm, ax=ax, cmap='Blues', annot=cm)\n",
    "        # ax.set_xticklabels('y_pred')\n",
    "        # ax.set_yticklabels('y_true')\n",
    "        ax.set_title(f'Confusion matrix at epoch: {self.current_epoch}')\n",
    "        self.logger.experiment.add_figure('confusion_matrix', fig, self.current_epoch)\n",
    "        plt.close(fig=fig)\n",
    "\n",
    "        self.validation_preds.clear()\n",
    "        self.validation_labels.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=1e-3)\n",
    "        lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': lr_scheduler,\n",
    "                'monitor':'val_loss'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "trainer = Trainer(\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(dirpath='checkpoints/radar_deeplabv3_effb0', filename='best', save_last=True, monitor='val_loss', mode='min'),\n",
    "        EarlyStopping(mode='min', monitor='val_loss', patience=10)\n",
    "    ],\n",
    "    logger=[TensorBoardLogger(save_dir='tb_logs', name='radar_deeplabv3_effb0')],\n",
    "    max_epochs=1000, gradient_clip_val=1.0, max_time=\"00:00:15:00\", precision=64\n",
    ")\n",
    "model = WrapperModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb6cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c39be",
   "metadata": {},
   "outputs": [],
   "source": [
    "private_test_dataloader = DataLoader(dataset=private_test_dataset,\n",
    "                              batch_size=36,\n",
    "                            #   sampler=\n",
    "                            shuffle=False,\n",
    "                            num_workers=0\n",
    "                            )\n",
    "trainer.validate(model, private_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae9fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_test_dataloader = DataLoader(dataset=public_test_dataset,\n",
    "                              batch_size=36,\n",
    "                            #   sampler=\n",
    "                            shuffle=False,\n",
    "                            num_workers=0\n",
    "                            )\n",
    "trainer.validate(model, public_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = [0,1,2,2,1,0,1,2,0,1]\n",
    "y_pred = [0,2,1,2,1,0,0,2,0,1]\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, None]  # normalize theo hàng\n",
    "\n",
    "labels = ['class0','class1','class2']\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_norm, \n",
    "            annot=cm, \n",
    "            # fmt='d', \n",
    "            cmap='Blues',\n",
    "            # annot_kws={'size':12}, cbar_kws={'format':'%.0f%%'},\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix (counts + %)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e76f2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mavclip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
